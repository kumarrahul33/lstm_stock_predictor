{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "         Open     High      Low    Close      MACD        ATR        RSI  \\\n",
      "1900  1283.21  1287.50  1256.98  1276.60 -4.820419  35.887857  30.130064   \n",
      "1901  1302.22  1330.74  1277.16  1330.74 -2.159744  32.133571  41.043854   \n",
      "1902  1334.63  1341.51  1298.42  1298.42 -3.087302  29.425714  33.795734   \n",
      "1903  1299.67  1330.67  1295.22  1329.51 -0.866801  27.663571  39.512096   \n",
      "1904  1333.66  1359.68  1330.29  1349.88 -0.276945  26.217143  55.488315   \n",
      "\n",
      "      EFFR        VIX       USDX  UNRATE  UMCSENT  \n",
      "1900  2.69  32.240002  71.459999     5.1     69.5  \n",
      "1901  2.16  25.790001  71.570000     5.1     69.5  \n",
      "1902  2.08  29.840000  72.139999     5.1     69.5  \n",
      "1903  2.22  26.620001  72.750000     5.1     69.5  \n",
      "1904  2.08  25.730000  72.949997     5.1     69.5  \n"
     ]
    }
   ],
   "source": [
    "def scale_data(data):\n",
    "    num_features = data.shape[1]\n",
    "    scale_params = np.zeros((num_features,2))\n",
    "    mins = np.min(data, axis=0);maxes=np.max(data, axis=0)\n",
    "    data = (data - mins) / (maxes - mins)\n",
    "    # for i in range(num_features):\n",
    "    #     min_val = np.min(data[:,i])\n",
    "    #     max_val = np.max(data[:,i])\n",
    "    #     scale_params[i,:] = [min_val, max_val]\n",
    "    #     data[:,i] = (data[:,i] - min_val) / (max_val - min_val)\n",
    "    return data, scale_params\n",
    "\n",
    "data_df = pd.read_csv(\"data/final_dataset.csv\")\n",
    "\n",
    "data_df = data_df.drop(['Date'], axis=1)\n",
    "data_df = data_df.iloc[1900:,:]\n",
    "data = np.nan_to_num(np.array(data_df, dtype=np.float32))\n",
    "print(np.isnan(data).any().item())\n",
    "data, scale_params = scale_data(data)\n",
    "print(np.isnan(data).any().item())\n",
    "data, scale_params = scale_data(np.nan_to_num(np.array(data_df, dtype=np.float32)))\n",
    "print(data_df.head())\n",
    "# print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3148, 8, 12]) torch.Size([788, 8, 12])\n"
     ]
    }
   ],
   "source": [
    "def create_sequence(data,seq_len):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for i in range(len(data)-seq_len-1):\n",
    "        x = data[i:(i+seq_len),:]\n",
    "        # print(x.shape)\n",
    "        y = data[i+seq_len,0]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs),np.array(ys)\n",
    "\n",
    "SEQ_LEN = 8\n",
    "inputs , targets = create_sequence(data,SEQ_LEN)\n",
    "inputs=torch.from_numpy(inputs);targets=torch.from_numpy(targets)\n",
    "\n",
    "# split the input data into train and test data\n",
    "train_size = int(0.8 * len(inputs))\n",
    "test_size = len(inputs) - train_size\n",
    "train_inputs, test_inputs = inputs[:train_size], inputs[train_size:]\n",
    "train_targets, test_targets = targets[:train_size], targets[train_size:]\n",
    "print(train_inputs.shape, test_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PricePredictor(nn.Module):\n",
    "    def __init__(self, input_size=12, hidden_layer_size=150, time_segment=5, output_size=1):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.time_segment_length = time_segment\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size,batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.cell_double = None\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        output,_ = self.lstm(input_seq)\n",
    "        predictions = self.linear(output[0])\n",
    "        # print(predictions.shape)\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16 \n",
    "train_dataset = TensorDataset(train_inputs, train_targets)\n",
    "test_dataset = TensorDataset(test_inputs, test_targets)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(len(train_loader))\n",
    "print(len(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.90948391\n",
      "Test loss: 1.16874623\n",
      "Test loss: 0.76405656\n",
      "Test loss: 0.55692214\n",
      "Test loss: 0.43613076\n",
      "Test loss: 0.35980216\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = PricePredictor()\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 30\n",
    "\n",
    "for i in range(epochs):\n",
    "    for seq, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(seq)\n",
    "        single_loss = loss_function(y_pred, targets)\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "    # if random.random() < 0.2 or i == 0:\n",
    "    #     print(f'epoch: {i:3} train loss: {single_loss.item():10.8f}')\n",
    "    \n",
    "    if(i%5==0):\n",
    "        # print the test loss\n",
    "        with torch.no_grad():\n",
    "            test_loss = 0\n",
    "            for seq, targets in test_loader:\n",
    "                y_pred = model(seq)\n",
    "                test_loss += loss_function(y_pred, targets)\n",
    "            print(f'Test loss: {test_loss.item():10.8f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
